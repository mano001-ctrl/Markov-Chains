import numpy as np

class MarkovChain(object):
    def __init__(self, transition_prob):
        """
        Initialize the MarkovChain instance.

        Parameters
        ----------
        transition_prob: dict
            A dict object representing the transition probabilities in 
            Markov Chain. Should be of the form: {'state1': {'state1': 
            0.1, 'state2': 0.4}, 'state2': {...}}
        """
        self.transition_prob = transition_prob
        self.states = list(transition_prob.keys())

    def next_state(self, current_state):
        """
        Returns the state of the random variable at the next time 
        instance.

        Parameters
        ----------
        current_state: str
            The current state of the system.
        """
        return np.random.choice(
            self.states, p=[self.transition_prob[current_state][next_state]
                            for next_state in self.states])

    def generate_states(self, current_state, no=10):
        """
        Generates the next states of the system.

        Parameters
        ----------
        current_state: str
            The state of the current random variable.

        no: int
            The number of future states to generate.
        """
        future_states = []
        for i in range(no):
            next_state = self.next_state(current_state)
            future_states.append(next_state)
            current_state = next_state
        return future_states

# Transition probabilities for financial market conditions
transition_prob = {
    'Bull Market': {'Bull Market': 0.7, 'Bear Market': 0.2, 'Stagnant Market': 0.1},
    'Bear Market': {'Bull Market': 0.1, 'Bear Market': 0.8, 'Stagnant Market': 0.1},
    'Stagnant Market': {'Bull Market': 0.2, 'Bear Market': 0.3, 'Stagnant Market': 0.5}
}

market_chain = MarkovChain(transition_prob=transition_prob)
print(market_chain.next_state(current_state='Bull Market'))
print(market_chain.generate_states(current_state='Bull Market', no=50))
